# -*- coding: utf-8 -*-
"""DS_Workflow_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ou_RuSOZS3wPcztjOU83v1UqB4olbg-p
"""

import pandas as pd

# Load the uploaded CSV sample
csv_path = "/mnt/car_reviews_full.csv"
df = pd.read_csv(csv_path)

# Get a preview and summary
df_preview = df.head()
df_info = df.info()
df_description = df.describe(include='all')

df_preview

"""## Clean Data"""

# Clean the dataset: fix column name and parse 'Helpful' column into useful numeric columns

# Rename the column "Brand" with trailing quote
df.rename(columns={"Brand\"": "Brand"}, inplace=True)

# Split 'Helpful' into two new columns: 'Helpful Votes' and 'Total Votes'
df[['Helpful Votes', 'Total Votes']] = df['Helpful'].str.split('/', expand=True).astype(int)

# Drop the original 'Helpful' column
df.drop(columns=['Helpful'], inplace=True)

# Display cleaned dataframe
df.head()

"""### Handling missing and irregular data points"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Convert sub-rating columns to integers
rating_columns = ['Rating','Comfort', 'Interior', 'Performance', 'Value', 'Exterior', 'Reliability']
# Replace non-numeric values (like em dash) with NaN
df[rating_columns] = df[rating_columns].replace('—', np.nan)

# Convert columns to float first (to allow NaNs), then to int where possible
df[rating_columns] = df[rating_columns].astype(float)

# Confirm conversion
print(df[rating_columns].dtypes)

"""## Visualizarion EDA

### Summary of Rating Column
"""

import matplotlib.pyplot as plt
# --- 1. Summary Statistics ---
print("📊 Summary of Sub-Ratings:")
print(df[rating_columns].describe())

# --- 2. Average Rating by Category ---
avg_ratings = df[rating_columns].mean().sort_values()
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=avg_ratings.values, y=avg_ratings.index, palette="coolwarm")

# Add text labels
for i, v in enumerate(avg_ratings.values):
    ax.text(v + 0.05, i, f"{v:.2f}", color='black', va='center')

plt.title("Average Ratings by Category")
plt.xlabel("Average Rating (1-5)")
plt.ylabel("Overall Mean Ratings")
plt.grid(True, axis='x')
plt.tight_layout()
plt.show()

"""### Distribution Histogram"""

plt.figure(figsize=(14, 8))
for i, col in enumerate(rating_columns, 1):
    plt.subplot(3, 3, i)
    counts = df[col].value_counts(normalize=True).sort_index() * 100  # Percentage
    ax = sns.barplot(x=counts.index, y=counts.values, color='skyblue')

    # Add percentage labels
    for idx, val in enumerate(counts.values):
        ax.text(idx, val + 0.5, f"{val:.1f}%", ha='center')

    plt.title(f"{col} Distribution (%)")
    plt.xlabel("Rating")
    plt.ylabel("Percentage")
    plt.ylim(0, 100)
plt.tight_layout()
plt.show()

"""Most Rating Distribution

*  Are biased towards the higher rating

### Correlation Heatmap
"""

# Correlation Heatmap ---
import warnings

# Suppress all warnings
warnings.filterwarnings("ignore")

corr = df[rating_columns].corr()

plt.figure(figsize=(8, 6))
sns.heatmap(corr, annot=True, cmap="YlGnBu", linewidths=0.5, vmin=0, vmax=1)
plt.title("📈 Correlation Between Rating Categories")
plt.tight_layout()
plt.show()

"""* Rating and Reliabilty highly related and kind of make sense
* 0.58 Reliability and Interior are least correlated
* Exterior and Overall Rating at 0.59 are least related

### Brand-wise or Model-wise Rating Analysis
"""

brand_ratings = df.groupby("Brand")['Rating'].mean().sort_values(ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=brand_ratings.values, y=brand_ratings.index, palette="viridis")

for i, v in enumerate(brand_ratings.values):
    plt.text(v + 0.05, i, f"{v:.2f}", va='center')

plt.title("Average Rating by Brand")
plt.xlabel("Rating")
plt.tight_layout()
plt.show()

"""* Porche is highly rated
* Landrover and Mitsubishi least rated
"""

# pip install vaderSentiment
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

# Analyze sentiment scores
df['Sentiment'] = df['Review Text'].apply(lambda x: analyzer.polarity_scores(str(x))['compound'])

# Plot sentiment distribution
plt.figure(figsize=(8, 5))
sns.histplot(df['Sentiment'], bins=10, kde=True, color='purple')
plt.title("Sentiment Score Distribution")
plt.xlabel("Compound Sentiment Score")
plt.show()

# Optional: label as Positive, Neutral, Negative
df['Sentiment Label'] = df['Sentiment'].apply(lambda x: 'Positive' if x > 0.05 else 'Negative' if x < -0.05 else 'Neutral')

"""* Sentiment is highly positive bcz rating highly biased

### Added country (Country-Brand-SentimentBased)
Brands create a data where the brands are related which origin country and then we can see the rating based on country and brands. And then sentiment based on brands and country

#### Average Rating by Country
"""

# Create a mapping of car brands to their countries of origin
brand_country_map = {
    'lincoln': 'USA',
    'volvo': 'Sweden',
    'bmw': 'Germany',
    'mercedes-benz': 'Germany',
    'audi': 'Germany',
    'lexus': 'Japan',
    'acura': 'Japan',
    'toyota': 'Japan',
    'honda': 'Japan',
    'chevrolet': 'USA',
    'ford': 'USA',
    'hyundai': 'South Korea',
    'kia': 'South Korea',
    'nissan': 'Japan',
    'mazda': 'Japan',
    'cadillac': 'USA',
    'chrysler': 'USA',
    'jeep': 'USA',
    'tesla': 'USA',
    'subaru': 'Japan',
    'volkswagen': 'Germany',
    'porsche': 'Germany',
    'jaguar': 'UK',
    'land rover': 'UK'
}

# Standardize brand names to lowercase
df['Brand'] = df['Brand'].str.lower().str.strip()

# Map brands to countries
df['Country'] = df['Brand'].map(brand_country_map)

# Show a few rows to confirm
df[['Brand', 'Country', 'Rating']].head()

# --- 1. Average Rating by Country ---
country_avg = df.groupby("Country")['Rating'].mean().sort_values()

plt.figure(figsize=(10, 6))
ax = sns.barplot(x=country_avg.values, y=country_avg.index, palette="coolwarm")

# Add text labels
for i, v in enumerate(country_avg.values):
    ax.text(v + 0.05, i, f"{v:.2f}", color='black', va='center')

plt.title("Average Car Rating by Country of Origin")
plt.xlabel("Average Rating (1–5)")
plt.tight_layout()
plt.show()

"""* Countries like Sweden and Japan tend to have higher-rated brands.
* USA has a broader spread in ratings, resulting in a moderate average.
* Japan is very competitive with consistently high scores.

#### Average Rating by Brand, Grouped by Country
"""

# --- 2. Average Rating by Brand, Grouped by Country ---

# Get average rating by Brand and Country
brand_country_rating = df.groupby(['Country', 'Brand'])['Rating'].mean().reset_index()

# Sort values for clean plotting
brand_country_rating = brand_country_rating.sort_values(by='Rating', ascending=False)

# Plot grouped bar chart
plt.figure(figsize=(14, 8))
sns.barplot(data=brand_country_rating, y='Brand', x='Rating', hue='Country', dodge=False, palette="tab10")

plt.title("Average Car Rating by Brand and Country")
plt.xlabel("Average Rating")
plt.ylabel("Brand")
plt.legend(title="Country", bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""#### Sentiment by Brand-Country-ReviewText"""

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Initialize VADER
analyzer = SentimentIntensityAnalyzer()

# Compute sentiment scores
df['Sentiment Score'] = df['Review Text'].astype(str).apply(lambda x: analyzer.polarity_scores(x)['compound'])

# Classify sentiment into categories
def label_sentiment(score):
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

df['Sentiment Label'] = df['Sentiment Score'].apply(label_sentiment)

# Sentiment distribution by brand and country
sentiment_counts = df.groupby(['Country', 'Brand', 'Sentiment Label']).size().reset_index(name='Count')

# Calculate percentage within each brand
total_by_brand = sentiment_counts.groupby(['Country', 'Brand'])['Count'].transform('sum')
sentiment_counts['Percentage'] = 100 * sentiment_counts['Count'] / total_by_brand

# Filter for top 10 brands by review count
top_brands = df['Brand'].value_counts().nlargest(10).index
top_sentiment = sentiment_counts[sentiment_counts['Brand'].isin(top_brands)]

# Pivot for plotting
pivot = top_sentiment.pivot_table(index=['Brand'], columns='Sentiment Label', values='Percentage', fill_value=0)
import matplotlib.pyplot as plt

# Reuse the pivoted data from previous step
pivot_plot = pivot[['Positive', 'Neutral', 'Negative']]

# Ensure all sentiment categories exist and reorder index to avoid plotting errors
pivot = pivot.reindex(columns=['Positive', 'Neutral', 'Negative'], fill_value=0)

# Plot with percentage labels
fig, ax = plt.subplots(figsize=(12, 8))
pivot.plot(kind='barh', stacked=True, ax=ax, colormap='coolwarm')

# Add percentage labels to each segment
for i, (index, row) in enumerate(pivot.iterrows()):
    cumulative = 0
    for sentiment in ['Positive', 'Neutral', 'Negative']:
        val = row[sentiment]
        if val > 0:
            ax.text(cumulative + val / 2, i, f"{val:.1f}%", va='center', ha='center', color='black', fontsize=9)
            cumulative += val

ax.set_xlabel("Percentage")
ax.set_title("Sentiment Distribution by Brand (with % Labels)")
ax.legend(title='Sentiment', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# Plot sentiment distribution by country
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='Country', y='Sentiment', palette='Set2')
plt.xticks(rotation=45)
plt.title("Sentiment Score Distribution by Country")
plt.ylabel("Compound Sentiment Score")
plt.xlabel("Country")
plt.tight_layout()
plt.show()

# Sentiment statistics per country
country_stats = df.groupby('Country')['Sentiment'].describe()

# Highest sentiment score (outlier)
top_outlier_country = country_stats['max'].idxmax()
top_outlier_value = country_stats['max'].max()

# Lowest sentiment score (outlier)
bottom_outlier_country = country_stats['min'].idxmin()
bottom_outlier_value = country_stats['min'].min()

# Countries with longest tails (using standard deviation)
long_tail_countries = country_stats['std'].sort_values(ascending=False).head(3)

# Top and bottom average sentiment
avg_sentiment = country_stats['mean'].sort_values(ascending=False)
top_sentiment_country = avg_sentiment.index[0]
lowest_sentiment_country = avg_sentiment.index[-1]

# Print results
print("🔼 Highest Sentiment Outlier:", top_outlier_country, round(top_outlier_value, 3))
print("🔽 Lowest Sentiment Outlier:", bottom_outlier_country, round(bottom_outlier_value, 3))
print("\n🎯 Longest Sentiment Tails (Top 3 Std Dev):")
print(long_tail_countries.round(3))
print("\n🏆 Top Average Sentiment Country:", top_sentiment_country, round(avg_sentiment.iloc[0], 3))
print("🚩 Lowest Average Sentiment Country:", lowest_sentiment_country, round(avg_sentiment.iloc[-1], 3))

"""#### German Car Sentiment Distribution"""

# Filter for German brands
german_df = df[df['Country'] == 'Germany']

# Group by brand and sentiment label
german_sentiment = german_df.groupby(['Brand', 'Sentiment Label']).size().reset_index(name='Count')

# Calculate percentage distribution
total_per_brand = german_sentiment.groupby('Brand')['Count'].transform('sum')
german_sentiment['Percentage'] = 100 * german_sentiment['Count'] / total_per_brand

# Pivot for bar plot
german_pivot = german_sentiment.pivot_table(index='Brand', columns='Sentiment Label', values='Percentage', fill_value=0)

# Reorder for consistent plotting
german_pivot = german_pivot.reindex(columns=['Positive', 'Neutral', 'Negative'], fill_value=0)

# Plot
ax = german_pivot.plot(kind='barh', stacked=True, figsize=(10, 6), colormap='coolwarm')

# Add percent labels
for i, (idx, row) in enumerate(german_pivot.iterrows()):
    cumulative = 0
    for sentiment in ['Positive', 'Neutral', 'Negative']:
        val = row[sentiment]
        if val > 0:
            ax.text(cumulative + val / 2, i, f"{val:.1f}%", va='center', ha='center', fontsize=9)
            cumulative += val

plt.title("🇩🇪 Sentiment Distribution for German Car Brands")
plt.xlabel("Percentage")
plt.tight_layout()
plt.show()

"""* Audi highly positive sentiments
* Volkswagen has high negative sentiments at 9.2 %

## Content-based rating predictions

### Goal: Predict whether a user would like or dislike a car based on its content.

Target Variable
Convert the original Rating (or sentiment score) into:

1 = "Liked" (e.g., Rating ≥ 4 or Sentiment ≥ 0.5)

0 = "Not Liked"

#### Based on Rating
"""

df['Liked'] = df['Rating'].apply(lambda x: 1 if x >= 4 else 0)
# Or, based on sentiment:
# df['Liked'] = df['Sentiment'].apply(lambda x: 1 if x >= 0.5 else 0)

"""Features (Content-Based)

* Brand (One-Hot)
* Country
* Ratings (Comfort, Performance, etc.)
* Review length
* Sentiment score
* Car Type
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score


features = df[['Brand', 'Comfort', 'Performance', 'Interior', 'Value', 'Sentiment','Liked']]
# 1. Feature engineering: One-hot encode categorical features
cat_features = ['Brand']
df_encoded = pd.get_dummies(features, columns=cat_features)

# 3. Prepare X and y
X = df_encoded.drop(columns=['Liked'])  # Drop target and ID
y = df_encoded['Liked']


# 3. Split data: train, validation, test
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val
)
# This results in 60% train, 20% val, 20% test

# 4. Train model on train set
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# 5. Validate model on validation set
y_val_pred = model.predict(X_val)
print("Validation Accuracy:", accuracy_score(y_val, y_val_pred))
print("Validation Classification Report:\n", classification_report(y_val, y_val_pred))

# 6. Test model on test set
y_test_pred = model.predict(X_test)
print("Test Accuracy:", accuracy_score(y_test, y_test_pred))
print("Test Classification Report:\n", classification_report(y_test, y_test_pred))

# Assuming original df (before one-hot) and predictions available
probs = model.predict_proba(X)[:, 1]

df_with_preds = df.copy()
df_with_preds['Like_Probability'] = probs

# Group by 'Car Model' and get average score
avg_scores = df_with_preds.groupby('Car Model')['Like_Probability'].mean().sort_values(ascending=False)

print("Top recommended car models overall:")
print(avg_scores.head(10))

print("Least recommended car models overall:")
print(avg_scores.tail(10))

"""* Bmw M6 (2013)   Bmw M6 (2016)      are higly recommended
* Mazda Cx 90 Phev (2025) and Tesla Cybertruck (2024) Badly reviewed by the model
"""

# 1. Average predicted like probability by Brand
brand_kpis = df_with_preds.groupby('Brand')['Like_Probability'].mean().sort_values(ascending=False)
print("Average predicted Like probability per Brand:")
print(brand_kpis)

# 2. Average predicted like probability by Car Model
model_kpis = df_with_preds.groupby('Car Model')['Like_Probability'].mean().sort_values(ascending=False)
print("\nAverage predicted Like probability per Car Model:")
print(model_kpis)

# 3. Optional: If you want to compare real KPIs (e.g., actual 'Liked' rates) by Brand/Model:
brand_actual = df_with_preds.groupby('Brand')['Liked'].mean().sort_values(ascending=False)
model_actual = df_with_preds.groupby('Car Model')['Liked'].mean().sort_values(ascending=False)

print("\nActual Like rate per Brand:")
print(brand_actual)

print("\nActual Like rate per Car Model:")
print(model_actual)

# Example: Bar plot of average predicted Like probability per Brand
plt.figure(figsize=(12,6))
brand_kpis.plot(kind='bar')
plt.title("Average Predicted Like Probability per Brand")
plt.ylabel("Avg Like Probability")
plt.xlabel("Brand")
plt.xticks(rotation=45)
plt.show()

#Statistical Testing Between Brands or Models
from scipy.stats import f_oneway

# Prepare list of arrays of like probabilities per brand
groups = [group['Like_Probability'].values for name, group in df_with_preds.groupby('Brand')]

# Perform ANOVA
f_stat, p_val = f_oneway(*groups)
print(f"ANOVA F-statistic: {f_stat:.4f}, p-value: {p_val:.4e}")

if p_val < 0.05:
    print("Significant differences exist between brands.")
else:
    print("No significant differences found between brands.")

from scipy.stats import ttest_ind

brand1 = df_with_preds[df_with_preds['Brand']=='BrandA']['Like_Probability']
brand2 = df_with_preds[df_with_preds['Brand']=='BrandB']['Like_Probability']

t_stat, p_val = ttest_ind(brand1, brand2)
print(f"T-test between BrandA and BrandB: t={t_stat:.4f}, p={p_val:.4e}")

def precision_at_k(y_true, y_scores, k):
    idx = np.argsort(y_scores)[::-1][:k]
    return y_true[idx].sum() / k

def recall_at_k(y_true, y_scores, k):
    idx = np.argsort(y_scores)[::-1][:k]
    return y_true[idx].sum() / y_true.sum() if y_true.sum() > 0 else 0

def calculate_metrics(df, group_col, k=10):
    groups = df[group_col].unique()
    precisions = {}
    recalls = {}

    for g in groups:
        group_df = df[df[group_col] == g]
        y_true = group_df['Liked'].values
        y_scores = group_df['Like_Probability'].values

        # Need enough samples and at least one positive for recall
        if len(y_true) >= k and y_true.sum() > 0:
            precisions[g] = precision_at_k(y_true, y_scores, k)
            recalls[g] = recall_at_k(y_true, y_scores, k)

    return precisions, recalls

k = 10

# Calculate for Brand
brand_precisions, brand_recalls = calculate_metrics(df_with_preds, 'Brand', k)

# Calculate for Car Model
model_precisions, model_recalls = calculate_metrics(df_with_preds, 'Car Model', k)

def plot_metrics(metrics_dict, title, ylabel, top_n=15):
    # Sort and take top N for better visualization
    sorted_metrics = dict(sorted(metrics_dict.items(), key=lambda item: item[1], reverse=True)[:top_n])

    plt.figure(figsize=(12,6))
    sns.barplot(x=list(sorted_metrics.keys()), y=list(sorted_metrics.values()), palette="viridis")
    plt.title(title)
    plt.ylabel(ylabel)
    plt.xlabel('')
    plt.xticks(rotation=45, ha='right')
    plt.ylim(0,1)
    plt.tight_layout()
    plt.show()

# Plot brand metrics
plot_metrics(brand_precisions, f'Precision@{k} by Brand', 'Precision@k')
plot_metrics(brand_recalls, f'Recall@{k} by Brand', 'Recall@k')

# Plot car model metrics (top 15)
plot_metrics(model_precisions, f'Precision@{k} by Car Model (Top 15)', 'Precision@k', top_n=15)
plot_metrics(model_recalls, f'Recall@{k} by Car Model (Top 15)', 'Recall@k', top_n=15)

"""### Rank Brands and Models by both Precision@10 and Recall@

Rank Brands and Models by both Precision@10 and Recall@10.

Combine them using a weighted score or just average.

Recommend the top N Brands and Models based on these KPIs
"""

import pandas as pd

def rank_and_recommend(precision_dict, recall_dict, top_n=5, alpha=0.5):
    # Convert to DataFrame
    df_metrics = pd.DataFrame({
        'Precision@10': precision_dict,
        'Recall@10': recall_dict
    })

    # Compute a combined score (you can tune alpha to weight precision vs recall)
    df_metrics['Combined_Score'] = alpha * df_metrics['Precision@10'] + (1 - alpha) * df_metrics['Recall@10']

    # Sort by combined score
    df_metrics_sorted = df_metrics.sort_values(by='Combined_Score', ascending=False)

    return df_metrics_sorted.head(top_n)

# Top 5 recommended Brands
top_brands = rank_and_recommend(brand_precisions, brand_recalls, top_n=5)
print("🏆 Top 5 Recommended Brands based on Precision@10 and Recall@10:")
print(top_brands)

# Top 5 recommended Car Models
top_models = rank_and_recommend(model_precisions, model_recalls, top_n=5)
print("\n🚗 Top 5 Recommended Car Models based on Precision@10 and Recall@10:")
print(top_models)

import matplotlib.pyplot as plt
import seaborn as sns

def plot_recommendations(df, title):
    plt.figure(figsize=(10,6))
    sns.barplot(x=df['Combined_Score'], y=df.index, palette="crest")
    plt.title(title)
    plt.xlabel("Combined Score (Precision@10 + Recall@10)")
    plt.ylabel("")
    plt.xlim(0, 1)
    plt.tight_layout()
    plt.show()

# Visualize top brands
plot_recommendations(top_brands, " Top 5 Recommended Brands")

# Visualize top car models
plot_recommendations(top_models, "Top 5 Recommended Car Models")

"""Tune Scoring Weights"""

# More precision-heavy (e.g., 70% precision, 30% recall)
top_brands_precision_weighted = rank_and_recommend(brand_precisions, brand_recalls, alpha=0.7)
top_models_precision_weighted = rank_and_recommend(model_precisions, model_recalls, alpha=0.7)

# More recall-heavy
top_brands_recall_weighted = rank_and_recommend(brand_precisions, brand_recalls, alpha=0.3)

top_brands_recall_weighted

top_models_precision_weighted

"""## Autoencoder-Based Recommendation (Content-Based)

✔️ Use Case:
You want to recommend similar car models to those that users tend to like, based on features like Comfort, Performance, Sentiment, etc.
"""

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

# Select relevant features (excluding user-related ones)
features = df_with_preds[['Comfort', 'Interior', 'Performance', 'Value', 'Sentiment Score']]
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(features)

# Define Autoencoder
input_dim = X_scaled.shape[1]
encoding_dim = 3

input_layer = Input(shape=(input_dim,))
encoded = Dense(encoding_dim, activation='relu')(input_layer)
decoded = Dense(input_dim, activation='sigmoid')(encoded)

autoencoder = Model(input_layer, decoded)
autoencoder.compile(optimizer='adam', loss='mse')

# Train Autoencoder
autoencoder.fit(X_scaled, X_scaled, epochs=10, batch_size=32, shuffle=True, verbose=0)

# Get Encoded Representations
encoder = Model(inputs=input_layer, outputs=encoded)
encoded_cars = encoder.predict(X_scaled)

# Add encoded vectors to dataframe
df_with_preds[['enc1', 'enc2', 'enc3']] = encoded_cars

# Find Top-N similar cars for a liked car (e.g., based on cosine distance)
from sklearn.metrics.pairwise import cosine_similarity

liked_cars = df_with_preds[df_with_preds['Liked'] == 1]
encoded_liked = liked_cars[['enc1', 'enc2', 'enc3']].values

# Average encoding for liked cars
avg_encoding = np.mean(encoded_liked, axis=0).reshape(1, -1)

# Compute similarity to all cars
similarities = cosine_similarity(df_with_preds[['enc1', 'enc2', 'enc3']], avg_encoding).flatten()
df_with_preds['Autoencoder_Score'] = similarities

# Recommend Top-N
recommended = df_with_preds.sort_values(by='Autoencoder_Score', ascending=False).head(10)
print(" Autoencoder-Based Top Recommendations:")
print(recommended[['Brand', 'Car Model', 'Autoencoder_Score']])

"""## Bayesian Personalized Ranking (BPR)"""

from lightfm import LightFM
from lightfm.data import Dataset

# Create a fake user-item matrix (e.g., using reviewer or location)
dataset = Dataset()
dataset.fit((x for x in df_with_preds['Reviewer']), (x for x in df_with_preds['Car Model']))

interactions = [(row['Reviewer'], row['Car Model']) for _, row in df_with_preds[df_with_preds['Liked'] == 1].iterrows()]
dataset.fit_partial(users=[r for r, _ in interactions], items=[c for _, c in interactions])

(interaction_matrix, _) = dataset.build_interactions(interactions)

# Train BPR model
model = LightFM(loss='bpr')
model.fit(interaction_matrix, epochs=10, num_threads=4)

# Recommend items for a sample user
from lightfm.evaluation import precision_at_k

print("📈 Model Precision@5:", precision_at_k(model, interaction_matrix, k=5).mean())

"""## Methods Summary

| Method                         | Description                                                          | Type          | Data Required                        | Strengths                                      | Weaknesses                                   |
| ------------------------------ | -------------------------------------------------------------------- | ------------- | ------------------------------------ | ---------------------------------------------- | -------------------------------------------- |
| **Precision\@k / Recall\@k**   | Rule-based evaluation on model scores (e.g., classifier outputs)     | Metric-based  | Labeled predictions per item         | Simple, interpretable, easy to track KPIs      | Not a recommender itself; just an evaluation |
| **Autoencoder Recommender**    | Learns compressed latent features to recommend similar items         | Content-based | Item attributes (e.g., car features) | No user info needed, unsupervised, scalable    | Doesn't capture preferences explicitly       |
| **BPR / Matrix Factorization** | Learns pairwise item preferences from (user, item) implicit feedback | Collaborative | User-item interaction matrix         | Great with sparse data, models personalization | Needs reliable user IDs or clustering        |

## Strengths and Weaknesses Comparison

|Method                       | Strengths                                             | Weaknesses                                                |
| ---------------------------- | ----------------------------------------------------- | --------------------------------------------------------- |
| **Precision\@k / Recall\@k** | Simple, interpretable for brands/KPI teams            | Not an actual recommender                                 |
| **Autoencoder**              | Learns deep item relationships, handles cold start    | Not personalized, assumes similarity = preference         |
| **BPR (LightFM)**            | Models implicit feedback, very strong personalization | Requires well-defined users; fails if no interaction data |

| Scenario                                   | Best Method              |
| ------------------------------------------ | ------------------------ |
| You want brand-level KPI evaluation        | Precision\@k / Recall\@k |
| You need item-to-item recommendations      | Autoencoder              |
| You want user-personalized recommendations | BPR (LightFM/ALS)        |
"""

df.columns

